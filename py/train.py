import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import mysql.connector
from datetime import datetime
from sklearn.preprocessing import LabelEncoder

# âœ… ì†ì„± ê°œìˆ˜ë¥¼ DBì—ì„œ ìë™ ì¡°íšŒí•˜ì—¬ embedding_dimìœ¼ë¡œ ì‚¬ìš©
def get_embedding_dims_from_db(conn):
    query = """
    SELECT a.name AS attribute_name, COUNT(av.id) AS count
    FROM attribute a
    JOIN attribute_value av ON a.id = av.attribute_id
    GROUP BY a.name
    """
    df = pd.read_sql(query, conn)
    return {row['attribute_name']: row['count'] for _, row in df.iterrows()}

# âœ… DBì—ì„œ ì „ì²´ í•™ìŠµ ë°ì´í„° ë¡œë”© ë° ë³‘í•©
def load_training_data(conn):
    # 1. ì¶”ì²œ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸°
    log_df = pd.read_sql("""
        SELECT user_id, model_id, product_id, weight, timestamp
        FROM recommend_log
    """, conn)
    log_df['timestamp'] = pd.to_datetime(log_df['timestamp']).apply(lambda x: int(x.timestamp()))

    # Min-Max ì •ê·œí™”
    ts_min = log_df['timestamp'].min()
    ts_max = log_df['timestamp'].max()
    log_df['timestamp'] = (log_df['timestamp'] - ts_min) / (ts_max - ts_min + 1e-9)

    # 2. ì‚¬ìš©ì ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
    user_df = pd.read_sql("""
        SELECT id AS user_id, gender, birth, residence_type
        FROM users
    """, conn)
    current_year = datetime.now().year
    user_df['age'] = current_year - pd.to_datetime(user_df['birth']).dt.year
    user_df['age_group'] = pd.cut(user_df['age'], bins=[-1, 9, 19, 29, 39, 49, 150], labels=[0, 1, 2, 3, 4, 5]).astype(
        int)
    user_df.drop(['birth', 'age'], axis=1, inplace=True)

    # 3. ì œí’ˆ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
    product_df = pd.read_sql("SELECT id AS product_id, category_id FROM product", conn)

    # 4. ëª¨ë¸ ì†ì„± ì •ë³´ (ìƒ‰ìƒ, ì‚¬ì´ì¦ˆ, ì†Œì¬)
    model_attr_df = pd.read_sql("""
        SELECT pma.product_model_id AS model_id, a.name AS attribute_type, av.value AS attribute_value
        FROM product_model_attribute pma
        JOIN attribute_value av ON pma.attribute_value_id = av.id
        JOIN attribute a ON av.attribute_id = a.id
    """, conn)
    model_pivot = model_attr_df.pivot_table(
        index='model_id',
        columns='attribute_type',
        values='attribute_value',
        aggfunc='first'
    ).reset_index()

    # ë³‘í•©
    df = log_df \
        .merge(user_df, on='user_id', how='left') \
        .merge(product_df, on='product_id', how='left') \
        .merge(model_pivot, on='model_id', how='left')

    # ğŸ” ê²°ì¸¡ì¹˜ ì œê±° (ì¶”ì²œ ë¡œê·¸ì— ì¡´ì¬í•˜ì§€ë§Œ, users/product/modelì— ì—†ëŠ” ê²½ìš° ì œê±°)
    df = df.dropna(subset=[
        'user_id', 'product_id', 'model_id',
        'gender', 'residence_type', 'age_group',
        'ìƒ‰ìƒ', 'ì‚¬ì´ì¦ˆ', 'ì†Œì¬'
    ])

    # ğŸ”„ ë²”ì£¼í˜• ë³€ìˆ˜ ì •ìˆ˜ ì¸ì½”ë”© (nan ë°©ì§€)
    for col in ['user_id', 'product_id', 'model_id',
                'gender', 'residence_type', 'ìƒ‰ìƒ', 'ì‚¬ì´ì¦ˆ', 'ì†Œì¬']:
        df[col] = df[col].astype(str)
        df[col] = LabelEncoder().fit_transform(df[col])

    # age_groupì€ ì´ë¯¸ intë¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    df['age_group'] = df['age_group'].astype(int)

    return df


# âœ… PyTorch Dataset ì •ì˜
class RecommendDataset(Dataset):
    def __init__(self, dataframe):
        self.data = dataframe.copy()
        self.features = self.data[[
            'user_id', 'product_id', 'model_id',
            'gender', 'age_group', 'residence_type',
            'ìƒ‰ìƒ', 'ì‚¬ì´ì¦ˆ', 'ì†Œì¬', 'timestamp'
        ]].values.astype(float)
        self.labels = self.data['weight'].values.astype(float)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        X = torch.tensor(self.features[idx], dtype=torch.float32)
        y = torch.tensor(self.labels[idx], dtype=torch.float32)
        return X, y

# âœ… ë”¥ëŸ¬ë‹ ëª¨ë¸ ì •ì˜

class DeepRecModel(nn.Module):
    def __init__(self, num_embeddings, embedding_dims):
        super().__init__()
        self.user_emb = nn.Embedding(num_embeddings['user_id'] + 1, 8)
        self.product_emb = nn.Embedding(num_embeddings['product_id'] + 1, 8)
        self.model_emb = nn.Embedding(num_embeddings['model_id'] + 1, 8)
        self.gender_emb = nn.Embedding(num_embeddings['gender'] + 1, 2)
        self.age_emb = nn.Embedding(num_embeddings['age_group'] + 1, 4)
        self.residence_emb = nn.Embedding(num_embeddings['residence_type'] + 1, 3)
        self.color_emb = nn.Embedding(embedding_dims['ìƒ‰ìƒ'] + 1, embedding_dims['ìƒ‰ìƒ'])
        self.size_emb = nn.Embedding(embedding_dims['ì‚¬ì´ì¦ˆ'] + 1, embedding_dims['ì‚¬ì´ì¦ˆ'])
        self.material_emb = nn.Embedding(embedding_dims['ì†Œì¬'] + 1, embedding_dims['ì†Œì¬'])

        total_input_dim = (
            8*3 + 2 + 4 + 3 +
            embedding_dims['ìƒ‰ìƒ'] + embedding_dims['ì‚¬ì´ì¦ˆ'] + embedding_dims['ì†Œì¬'] + 1
        )

        self.mlp = nn.Sequential(
            nn.Linear(total_input_dim, 16),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(16, 4),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(4, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        uid = x[:, 0].long()
        pid = x[:, 1].long()
        mid = x[:, 2].long()
        gender = x[:, 3].long()
        age = x[:, 4].long()
        res = x[:, 5].long()
        color = x[:, 6].long()
        size = x[:, 7].long()
        mat = x[:, 8].long()
        time = x[:, 9].unsqueeze(1)

        try:
            x = torch.cat([
                self.user_emb(uid), self.product_emb(pid), self.model_emb(mid),
                self.gender_emb(gender), self.age_emb(age), self.residence_emb(res),
                self.color_emb(color), self.size_emb(size), self.material_emb(mat),
                time
            ], dim=-1)
        except IndexError as e:
            print("ğŸ”¥ IndexError ë°œìƒ! ì•„ë˜ ì¸ë±ìŠ¤ë“¤ì„ í™•ì¸í•˜ì„¸ìš”")
            print("user_id:", uid.tolist())
            print("product_id:", pid.tolist())
            print("model_id:", mid.tolist())
            print("gender:", gender.tolist())
            print("age_group:", age.tolist())
            print("residence_type:", res.tolist())
            print("ìƒ‰ìƒ:", color.tolist())
            print("ì‚¬ì´ì¦ˆ:", size.tolist())
            print("ì†Œì¬:", mat.tolist())
            raise e

        return self.mlp(x).squeeze()

# âœ… í•™ìŠµ ì‹œì‘
if __name__ == "__main__":
    conn = mysql.connector.connect(
        host="localhost",
        port=3306,
        user="root",
        password="1234",
        database="woorizip"
    )

    # ìë™ ì„ë² ë”© í¬ê¸° ì¶”ì¶œ
    embedding_dims = get_embedding_dims_from_db(conn)
    df = load_training_data(conn)
    conn.close()

    df.to_csv("train_data.csv", index=False)
    print("ğŸ“ train_data.csv ì €ì¥ ì™„ë£Œ (ì—…ë¡œë“œí•˜ì—¬ Colabì—ì„œ ì‚¬ìš© ê°€ëŠ¥)")

    dataset = RecommendDataset(df)
    train_loader = DataLoader(dataset, batch_size=32, shuffle=True)

    num_embeddings = {
        'user_id': int(df['user_id'].max()) + 1,
        'product_id': int(df['product_id'].max()) + 1,
        'model_id': int(df['model_id'].max()) + 1,
        'gender': int(df['gender'].max()) + 1,
        'age_group': int(df['age_group'].max()) + 1,
        'residence_type': int(df['residence_type'].max()) + 1,
        'ìƒ‰ìƒ': int(df['ìƒ‰ìƒ'].max()) + 1,
        'ì‚¬ì´ì¦ˆ': int(df['ì‚¬ì´ì¦ˆ'].max()) + 1,
        'ì†Œì¬': int(df['ì†Œì¬'].max()) + 1
    }

    model = DeepRecModel(num_embeddings, embedding_dims)
    device = torch.device("cpu")
    model = model.to(device)

    criterion = nn.BCELoss(reduction='none')
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    for epoch in range(10):
        model.train()
        total_loss = 0
        total_correct = 0
        total_samples = 0

        for X, y in train_loader:
            X, y = X.to(device), y.to(device)
            sample_weight = y.clone()
            pred = model(X)

            # â¬‡ï¸ accuracy ê³„ì‚°
            predicted_labels = (pred > 0.5).float()
            correct = (predicted_labels == (y > 0).float()).sum().item()
            total_correct += correct
            total_samples += y.size(0)

            # loss ê³„ì‚°
            loss = criterion(pred, (y > 0).float())
            weighted_loss = (loss * sample_weight).mean()

            optimizer.zero_grad()
            weighted_loss.backward()
            optimizer.step()
            total_loss += weighted_loss.item()

        acc = total_correct / total_samples if total_samples else 0
        print(f"Epoch {epoch + 1}/10 - Loss: {total_loss:.4f} - Accuracy: {acc:.4f}")

    # í•„ìš” ì‹œ ëª¨ë¸ ì €ì¥
    # torch.save(model.state_dict(), "deeprec_model.pt")
