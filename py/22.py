import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import mysql.connector
from datetime import datetime
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import numpy as np
import random

def set_seed(seed=0):
    random.seed(seed)                          # Python random Î™®Îìà
    np.random.seed(seed)                       # NumPy
    torch.manual_seed(seed)                    # PyTorch CPU
    torch.cuda.manual_seed(seed)               # PyTorch GPU (Îã®Ïùº)
    torch.cuda.manual_seed_all(seed)           # PyTorch GPU (Î©ÄÌã∞)
    torch.backends.cudnn.deterministic = True  # Ïó∞ÏÇ∞ Í≤∞Í≥º Í≥†Ï†ï
    torch.backends.cudnn.benchmark = False     # ÏÑ±Îä• ÎåÄÏã† ÏùºÍ¥ÄÏÑ± Ïö∞ÏÑ†

# ‚úÖ ÏÜçÏÑ± Í∞úÏàòÎ•º DBÏóêÏÑú ÏûêÎèô Ï°∞ÌöåÌïòÏó¨ embedding_dimÏúºÎ°ú ÏÇ¨Ïö©
def get_embedding_dims_from_db(conn):
    query = '''
            SELECT a.name AS attribute_name, COUNT(av.id) AS count
            FROM attribute a
                JOIN attribute_value av
            ON a.id = av.attribute_id
            GROUP BY a.name \
            '''
    df = pd.read_sql(query, conn)
    return {row['attribute_name']: row['count'] for _, row in df.iterrows()}

# ‚úÖ DBÏóêÏÑú Ï†ÑÏ≤¥ ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Î°úÎî© Î∞è Î≥ëÌï©
def load_training_data(conn):
    log_df = pd.read_sql("""
                         SELECT user_id, model_id, product_id, weight, timestamp
                         FROM recommend_log
                         """, conn)
    log_df['timestamp'] = pd.to_datetime(log_df['timestamp']).apply(lambda x: int(x.timestamp()))
    ts_min = log_df['timestamp'].min()
    ts_max = log_df['timestamp'].max()
    log_df['timestamp'] = (log_df['timestamp'] - ts_min) / (ts_max - ts_min + 1e-9)

    user_df = pd.read_sql("""
                          SELECT id AS user_id, gender, birth, residence_type
                          FROM users
                          """, conn)
    current_year = datetime.now().year
    user_df['age'] = current_year - pd.to_datetime(user_df['birth']).dt.year
    user_df['age_group'] = pd.cut(user_df['age'], bins=[-1, 9, 19, 29, 39, 49, 150], labels=[0, 1, 2, 3, 4, 5]).astype(
        int)
    user_df.drop(['birth', 'age'], axis=1, inplace=True)

    product_df = pd.read_sql("SELECT id AS product_id, category_id FROM product", conn)

    model_attr_df = pd.read_sql("""
                                SELECT pma.product_model_id AS model_id,
                                       a.name               AS attribute_type,
                                       av.value             AS attribute_value
                                FROM product_model_attribute pma
                                         JOIN attribute_value av ON pma.attribute_value_id = av.id
                                         JOIN attribute a ON av.attribute_id = a.id
                                """, conn)
    model_pivot = model_attr_df.pivot_table(
        index='model_id',
        columns='attribute_type',
        values='attribute_value',
        aggfunc='first'
    ).reset_index()

    df = log_df.merge(user_df, on='user_id', how='left').merge(product_df, on='product_id', how='left').merge(
        model_pivot, on='model_id', how='left')

    df = df.dropna(subset=[
        'user_id', 'product_id', 'model_id',
        'gender', 'residence_type', 'age_group',
        'ÏÉâÏÉÅ', 'ÏÇ¨Ïù¥Ï¶à', 'ÏÜåÏû¨'
    ])

    for col in ['user_id', 'product_id', 'model_id',
                'gender', 'residence_type', 'ÏÉâÏÉÅ', 'ÏÇ¨Ïù¥Ï¶à', 'ÏÜåÏû¨']:
        df[col] = df[col].astype(str)
        df[col] = LabelEncoder().fit_transform(df[col])
    df['age_group'] = df['age_group'].astype(int)

    return df


class RecommendDataset(Dataset):
    def __init__(self, dataframe):
        self.data = dataframe.copy()

        # Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞ (Í∏∞Î≥∏ ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥, Ï†úÌíà Ï†ïÎ≥¥, ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ Îì±)
        self.features = self.data[['user_id', 'product_id', 'model_id',
                                   'gender', 'age_group', 'residence_type',
                                   'ÏÉâÏÉÅ', 'ÏÇ¨Ïù¥Ï¶à', 'ÏÜåÏû¨', 'timestamp']].values.astype(float)

        # Î†àÏù¥Î∏î (Íµ¨Îß§ Ïó¨Î∂Ä, weight)
        self.labels = self.data['weight'].values.astype(float)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        X = torch.tensor(self.features[idx], dtype=torch.float32)
        y = torch.tensor(self.labels[idx], dtype=torch.float32)
        return X, y


class DeepRecModel(nn.Module):
    def __init__(self, num_embeddings, embedding_dims):
        super().__init__()

        # Í∞Å ÏûÑÎ≤†Îî© Î†àÏù¥Ïñ¥
        self.user_emb = nn.Embedding(num_embeddings['user_id'] + 1, 4)
        self.product_emb = nn.Embedding(num_embeddings['product_id'] + 1, 4)
        self.model_emb = nn.Embedding(num_embeddings['model_id'] + 1, 4)
        self.gender_emb = nn.Embedding(num_embeddings['gender'] + 1, 2)
        self.age_emb = nn.Embedding(num_embeddings['age_group'] + 1, 4)
        self.residence_emb = nn.Embedding(num_embeddings['residence_type'] + 1, 3)
        self.color_emb = nn.Embedding(embedding_dims['ÏÉâÏÉÅ'] + 1, embedding_dims['ÏÉâÏÉÅ'])
        self.size_emb = nn.Embedding(embedding_dims['ÏÇ¨Ïù¥Ï¶à'] + 1, embedding_dims['ÏÇ¨Ïù¥Ï¶à'])
        self.material_emb = nn.Embedding(embedding_dims['ÏÜåÏû¨'] + 1, embedding_dims['ÏÜåÏû¨'])

        # ÏûÑÎ≤†Îî© ÌõÑ Ï†ÑÏ≤¥ ÏûÖÎ†• Ï∞®Ïõê Í≥ÑÏÇ∞
        total_input_dim = (
                4 * 3 + 2 + 4 + 3 +  # ÏûÑÎ≤†Îî© Ï∞®Ïõê
                embedding_dims['ÏÉâÏÉÅ'] + embedding_dims['ÏÇ¨Ïù¥Ï¶à'] + embedding_dims['ÏÜåÏû¨'] + 1  # ÏÉâÏÉÅ, ÏÇ¨Ïù¥Ï¶à, ÏÜåÏû¨, timestamp
        )

        # MLP Î†àÏù¥Ïñ¥
        self.mlp = nn.Sequential(
            nn.Linear(total_input_dim, 8),
            nn.ReLU(),
            nn.Linear(8, 8),
            nn.ReLU(),
            nn.Linear(8, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        # Í∞Å ÏûÑÎ≤†Îî© ÏûÖÎ†•
        uid = x[:, 0].long()
        pid = x[:, 1].long()
        mid = x[:, 2].long()
        gender = x[:, 3].long()
        age = x[:, 4].long()
        res = x[:, 5].long()
        color = x[:, 6].long()
        size = x[:, 7].long()
        mat = x[:, 8].long()
        time = x[:, 9].unsqueeze(1)  # timestamp

        # ÏûÑÎ≤†Îî© Î†àÏù¥Ïñ¥ Ïó∞Í≤∞
        x = torch.cat([
            self.user_emb(uid), self.product_emb(pid), self.model_emb(mid),
            self.gender_emb(gender), self.age_emb(age), self.residence_emb(res),
            self.color_emb(color), self.size_emb(size), self.material_emb(mat),
            time
        ], dim=-1)

        return self.mlp(x).squeeze()  # ÏòàÏ∏° Ï∂úÎ†•


# ÌïôÏäµ ÏΩîÎìú
if __name__ == "__main__":
    conn = mysql.connector.connect(
        host="localhost", port=3306,
        user="root", password="1234",
        database="woorizip"
    )

    embedding_dims = get_embedding_dims_from_db(conn)
    df = load_training_data(conn)
    conn.close()

    # ÏÇ¨Ïö©Ïûê Í∏∞Ï§Ä train/val Î∂ÑÎ¶¨
    user_ids = df['user_id'].unique()
    train_user_ids, val_user_ids = train_test_split(user_ids, test_size=0.2, random_state=42)
    train_df = df[df['user_id'].isin(train_user_ids)].reset_index(drop=True)
    val_df = df[df['user_id'].isin(val_user_ids)].reset_index(drop=True)

    train_dataset = RecommendDataset(train_df)
    val_dataset = RecommendDataset(val_df)
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

    num_embeddings = {
        'user_id': int(df['user_id'].max()) + 1,
        'product_id': int(df['product_id'].max()) + 1,
        'model_id': int(df['model_id'].max()) + 1,
        'gender': int(df['gender'].max()) + 1,
        'age_group': int(df['age_group'].max()) + 1,
        'residence_type': int(df['residence_type'].max()) + 1,
        'ÏÉâÏÉÅ': int(df['ÏÉâÏÉÅ'].max()) + 1,
        'ÏÇ¨Ïù¥Ï¶à': int(df['ÏÇ¨Ïù¥Ï¶à'].max()) + 1,
        'ÏÜåÏû¨': int(df['ÏÜåÏû¨'].max()) + 1
    }

    model = DeepRecModel(num_embeddings, embedding_dims)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    criterion = nn.BCELoss(reduction='none')
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    for epoch in range(20):
        model.train()
        total_loss = 0
        total_correct = 0
        total_samples = 0
        for X, y in train_loader:
            X, y = X.to(device), y.to(device)
            sample_weight = y.clone()
            pred = model(X)
            predicted_labels = (pred > 0.5).float()
            correct = (predicted_labels == (y > 0).float()).sum().item()
            total_correct += correct
            total_samples += y.size(0)
            loss = criterion(pred, (y > 0).float())
            weighted_loss = (loss * sample_weight).mean()
            optimizer.zero_grad()
            weighted_loss.backward()
            optimizer.step()
            total_loss += weighted_loss.item()
        acc = total_correct / total_samples if total_samples else 0
        print(f"[Train] Epoch {epoch + 1} - Loss: {total_loss:.4f} - Acc: {acc:.4f}")

        model.eval()
        val_loss = 0
        val_correct = 0
        val_samples = 0
        with torch.no_grad():
            for X, y in val_loader:
                X, y = X.to(device), y.to(device)
                pred = model(X)
                predicted_labels = (pred > 0.5).float()
                correct = (predicted_labels == (y > 0).float()).sum().item()
                val_correct += correct
                val_samples += y.size(0)
                loss = criterion(pred, (y > 0).float())
                weighted_loss = (loss * y).mean()
                val_loss += weighted_loss.item()
        val_acc = val_correct / val_samples if val_samples else 0
        print(f"[Valid] Epoch {epoch + 1} - Loss: {val_loss:.4f} - Acc: {val_acc:.4f}")

    torch.save(model.state_dict(), "deeprec_model.pt")

    # ‚úÖ Precision@5, AUC Í≥ÑÏÇ∞ Ìï®Ïàò
    from sklearn.metrics import roc_auc_score


    def get_pytorch_precision_at_k(model, df, k=5):
        model.eval()
        user_ids = df['user_id'].unique()
        item_ids = df['model_id'].unique()
        precisions = []

        with torch.no_grad():
            for user_id in user_ids:
                user_data = df[df['user_id'] == user_id]
                seen_items = set(user_data['model_id'].values)
                candidate_items = [i for i in item_ids if i not in seen_items]

                if not candidate_items:
                    continue

                rows = []
                for item_id in candidate_items:
                    base = user_data.iloc[0].copy()
                    base['model_id'] = item_id
                    base['product_id'] = df[df['model_id'] == item_id]['product_id'].values[0]
                    rows.append(base)

                input_df = pd.DataFrame(rows)
                X = input_df[['user_id', 'product_id', 'model_id', 'gender', 'age_group',
                              'residence_type', 'ÏÉâÏÉÅ', 'ÏÇ¨Ïù¥Ï¶à', 'ÏÜåÏû¨', 'timestamp']].values
                X_tensor = torch.tensor(X, dtype=torch.float32)
                X_tensor = X_tensor.to(device)
                preds = model(X_tensor).cpu().numpy()  # GPU‚ÜíCPU Î≥ÄÌôò ÌõÑ numpy

                top_k_idx = preds.argsort()[::-1][:k]
                top_k_items = input_df.iloc[top_k_idx]['model_id'].values
                relevant_items = set(df[(df['user_id'] == user_id) & (df['weight'] > 0)]['model_id'])

                hit = sum([1 for item in top_k_items if item in relevant_items])
                precisions.append(hit / k)

        return sum(precisions) / len(precisions)


    def get_pytorch_auc(model, dataset):
        model.eval()
        y_true, y_score = [], []

        with torch.no_grad():
            for X, y in DataLoader(dataset, batch_size=64):
                X, y = X.to(device), y.to(device)
                pred = model(X).cpu().numpy()

                y_true.extend((y == 3).int().cpu().numpy())  # 3Ïù¥Î©¥ 1, ÏïÑÎãàÎ©¥ 0
                y_score.extend(pred)

        y_true = np.array(y_true)
        y_score = np.array(y_score)

        if len(np.unique(y_true)) < 2:  # ÌÅ¥ÎûòÏä§Í∞Ä ÌïòÎÇòÎßå ÏûàÏùÑ Í≤ΩÏö∞
            print("‚ö†Ô∏è AUC Í≥ÑÏÇ∞ Î∂àÍ∞Ä: y_trueÏóê ÌÅ¥ÎûòÏä§Í∞Ä ÌïòÎÇòÎøêÏûÖÎãàÎã§.")
            return 0.0  # AUC Í≥ÑÏÇ∞ Î∂àÍ∞Ä

        try:
            auc = roc_auc_score(y_true, y_score)
        except Exception as e:
            print(f"‚ö†Ô∏è AUC Í≥ÑÏÇ∞ Ï§ë Ïò§Î•ò: {e}")
            auc = 0.0

        return auc


    # ‚úÖ ÌèâÍ∞Ä Ïã§Ìñâ
    pt_precision = get_pytorch_precision_at_k(model, df, k=5)
    pt_auc = get_pytorch_auc(model, RecommendDataset(df))
    print(f"üìä Precision@5: {pt_precision:.4f}")
    print(f"üìä AUC Score: {pt_auc:.4f}")
