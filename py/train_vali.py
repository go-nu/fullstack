import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import mysql.connector
from datetime import datetime
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import numpy as np
import random

def set_seed(seed=0):
    random.seed(seed)                          # Python random ëª¨ë“ˆ
    np.random.seed(seed)                       # NumPy
    torch.manual_seed(seed)                    # PyTorch CPU
    torch.cuda.manual_seed(seed)               # PyTorch GPU (ë‹¨ì¼)
    torch.cuda.manual_seed_all(seed)           # PyTorch GPU (ë©€í‹°)
    torch.backends.cudnn.deterministic = True  # ì—°ì‚° ê²°ê³¼ ê³ ì •
    torch.backends.cudnn.benchmark = False     # ì„±ëŠ¥ ëŒ€ì‹  ì¼ê´€ì„± ìš°ì„ 

# âœ… ì†ì„± ê°œìˆ˜ë¥¼ DBì—ì„œ ìë™ ì¡°íšŒí•˜ì—¬ embedding_dimìœ¼ë¡œ ì‚¬ìš©
def get_embedding_dims_from_db(conn):
    query = '''
            SELECT a.name AS attribute_name, COUNT(av.id) AS count
            FROM attribute a
                JOIN attribute_value av
            ON a.id = av.attribute_id
            GROUP BY a.name \
            '''
    df = pd.read_sql(query, conn)
    return {row['attribute_name']: row['count'] for _, row in df.iterrows()}

# âœ… DBì—ì„œ ì „ì²´ í•™ìŠµ ë°ì´í„° ë¡œë”© ë° ë³‘í•©
def load_training_data(conn):
    log_df = pd.read_sql("""
                         SELECT user_id, model_id, product_id, weight, timestamp
                         FROM recommend_log
                         """, conn)
    log_df['timestamp'] = pd.to_datetime(log_df['timestamp']).apply(lambda x: int(x.timestamp()))
    ts_min = log_df['timestamp'].min()
    ts_max = log_df['timestamp'].max()
    log_df['timestamp'] = (log_df['timestamp'] - ts_min) / (ts_max - ts_min + 1e-9)

    user_df = pd.read_sql("""
                          SELECT id AS user_id, gender, birth, residence_type
                          FROM users
                          """, conn)
    current_year = datetime.now().year
    user_df['age'] = current_year - pd.to_datetime(user_df['birth']).dt.year
    user_df['age_group'] = pd.cut(user_df['age'], bins=[-1, 9, 19, 29, 39, 49, 150], labels=[0, 1, 2, 3, 4, 5]).astype(
        int)
    user_df.drop(['birth', 'age'], axis=1, inplace=True)

    product_df = pd.read_sql("SELECT id AS product_id, category_id FROM product", conn)

    model_attr_df = pd.read_sql("""
                                SELECT pma.product_model_id AS model_id,
                                       a.name               AS attribute_type,
                                       av.value             AS attribute_value
                                FROM product_model_attribute pma
                                         JOIN attribute_value av ON pma.attribute_value_id = av.id
                                         JOIN attribute a ON av.attribute_id = a.id
                                """, conn)
    model_pivot = model_attr_df.pivot_table(
        index='model_id',
        columns='attribute_type',
        values='attribute_value',
        aggfunc='first'
    ).reset_index()

    df = log_df.merge(user_df, on='user_id', how='left').merge(product_df, on='product_id', how='left').merge(
        model_pivot, on='model_id', how='left')

    df = df.dropna(subset=[
        'user_id', 'product_id', 'model_id',
        'gender', 'residence_type', 'age_group',
        'ìƒ‰ìƒ', 'ì‚¬ì´ì¦ˆ', 'ì†Œì¬'
    ])

    for col in ['user_id', 'product_id', 'model_id',
                'gender', 'residence_type', 'ìƒ‰ìƒ', 'ì‚¬ì´ì¦ˆ', 'ì†Œì¬']:
        df[col] = df[col].astype(str)
        df[col] = LabelEncoder().fit_transform(df[col])
    df['age_group'] = df['age_group'].astype(int)

    return df


class RecommendDataset(Dataset):
    def __init__(self, dataframe):
        self.data = dataframe.copy()
        self.features = self.data[[
            'user_id', 'product_id', 'model_id',
            'gender', 'age_group', 'residence_type',
            'ìƒ‰ìƒ', 'ì‚¬ì´ì¦ˆ', 'ì†Œì¬', 'timestamp'
        ]].values.astype(float)
        self.labels = self.data['weight'].values.astype(float)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        X = torch.tensor(self.features[idx], dtype=torch.float32)
        y = torch.tensor(self.labels[idx], dtype=torch.float32)
        return X, y


class DeepRecModel(nn.Module):
    def __init__(self, num_embeddings, embedding_dims):
        super().__init__()
        self.user_emb = nn.Embedding(num_embeddings['user_id'] + 1, 4)
        self.product_emb = nn.Embedding(num_embeddings['product_id'] + 1, 4)
        self.model_emb = nn.Embedding(num_embeddings['model_id'] + 1, 4)
        self.gender_emb = nn.Embedding(num_embeddings['gender'] + 1, 2)
        self.age_emb = nn.Embedding(num_embeddings['age_group'] + 1, 4)
        self.residence_emb = nn.Embedding(num_embeddings['residence_type'] + 1, 3)
        self.color_emb = nn.Embedding(embedding_dims['ìƒ‰ìƒ'] + 1, embedding_dims['ìƒ‰ìƒ'])
        self.size_emb = nn.Embedding(embedding_dims['ì‚¬ì´ì¦ˆ'] + 1, embedding_dims['ì‚¬ì´ì¦ˆ'])
        self.material_emb = nn.Embedding(embedding_dims['ì†Œì¬'] + 1, embedding_dims['ì†Œì¬'])

        total_input_dim = (
                4 * 3 + 2 + 4 + 3 +
                embedding_dims['ìƒ‰ìƒ'] + embedding_dims['ì‚¬ì´ì¦ˆ'] + embedding_dims['ì†Œì¬'] + 1
        )

        self.mlp = nn.Sequential(
            nn.Linear(total_input_dim, 8),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(8, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        uid = x[:, 0].long()
        pid = x[:, 1].long()
        mid = x[:, 2].long()
        gender = x[:, 3].long()
        age = x[:, 4].long()
        res = x[:, 5].long()
        color = x[:, 6].long()
        size = x[:, 7].long()
        mat = x[:, 8].long()
        time = x[:, 9].unsqueeze(1)

        x = torch.cat([
            self.user_emb(uid), self.product_emb(pid), self.model_emb(mid),
            self.gender_emb(gender), self.age_emb(age), self.residence_emb(res),
            self.color_emb(color), self.size_emb(size), self.material_emb(mat),
            time
        ], dim=-1)

        return self.mlp(x).squeeze()


if __name__ == "__main__":
    conn = mysql.connector.connect(
        host="localhost", port=3306,
        user="root", password="1234",
        database="woorizip"
    )

    embedding_dims = get_embedding_dims_from_db(conn)
    df = load_training_data(conn)
    conn.close()

    # df.to_csv("train_data.csv", index=False)
    # print("ğŸ“ train_data.csv ì €ì¥ ì™„ë£Œ (ì—…ë¡œë“œí•˜ì—¬ Colabì—ì„œ ì‚¬ìš© ê°€ëŠ¥)")

    # âœ… ì‚¬ìš©ì ê¸°ì¤€ train/val ë¶„ë¦¬
    user_ids = df['user_id'].unique()
    train_user_ids, val_user_ids = train_test_split(user_ids, test_size=0.2, random_state=42)
    train_df = df[df['user_id'].isin(train_user_ids)].reset_index(drop=True)
    val_df = df[df['user_id'].isin(val_user_ids)].reset_index(drop=True)

    train_dataset = RecommendDataset(train_df)
    val_dataset = RecommendDataset(val_df)
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

    num_embeddings = {
        'user_id': int(df['user_id'].max()) + 1,
        'product_id': int(df['product_id'].max()) + 1,
        'model_id': int(df['model_id'].max()) + 1,
        'gender': int(df['gender'].max()) + 1,
        'age_group': int(df['age_group'].max()) + 1,
        'residence_type': int(df['residence_type'].max()) + 1,
        'ìƒ‰ìƒ': int(df['ìƒ‰ìƒ'].max()) + 1,
        'ì‚¬ì´ì¦ˆ': int(df['ì‚¬ì´ì¦ˆ'].max()) + 1,
        'ì†Œì¬': int(df['ì†Œì¬'].max()) + 1
    }

    model = DeepRecModel(num_embeddings, embedding_dims)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    criterion = nn.BCELoss(reduction='none')
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    for epoch in range(20):
        model.train()
        total_loss = 0
        total_correct = 0
        total_samples = 0
        for X, y in train_loader:
            X, y = X.to(device), y.to(device)
            sample_weight = y.clone()
            pred = model(X)
            predicted_labels = (pred > 0.5).float()
            correct = (predicted_labels == (y > 0).float()).sum().item()
            total_correct += correct
            total_samples += y.size(0)
            loss = criterion(pred, (y > 0).float())
            weighted_loss = (loss * sample_weight).mean()
            optimizer.zero_grad()
            weighted_loss.backward()
            optimizer.step()
            total_loss += weighted_loss.item()
        acc = total_correct / total_samples if total_samples else 0
        print(f"[Train] Epoch {epoch + 1} - Loss: {total_loss:.4f} - Acc: {acc:.4f}")

        model.eval()
        val_loss = 0
        val_correct = 0
        val_samples = 0
        with torch.no_grad():
            for X, y in val_loader:
                X, y = X.to(device), y.to(device)
                pred = model(X)
                predicted_labels = (pred > 0.5).float()
                correct = (predicted_labels == (y > 0).float()).sum().item()
                val_correct += correct
                val_samples += y.size(0)
                loss = criterion(pred, (y > 0).float())
                weighted_loss = (loss * y).mean()
                val_loss += weighted_loss.item()
        val_acc = val_correct / val_samples if val_samples else 0
        print(f"[Valid] Epoch {epoch + 1} - Loss: {val_loss:.4f} - Acc: {val_acc:.4f}")

    torch.save(model.state_dict(), "deeprec_model.pt")

    # âœ… PyTorch ëª¨ë¸ Precision@5, AUC ê³„ì‚° í•¨ìˆ˜
    from sklearn.metrics import roc_auc_score


    def get_pytorch_precision_at_k(model, df, k=5):
        model.eval()
        user_ids = df['user_id'].unique()
        item_ids = df['model_id'].unique()
        precisions = []

        with torch.no_grad():
            for user_id in user_ids:
                user_data = df[df['user_id'] == user_id]
                seen_items = set(user_data['model_id'].values)
                candidate_items = [i for i in item_ids if i not in seen_items]

                if not candidate_items:
                    continue

                rows = []
                for item_id in candidate_items:
                    base = user_data.iloc[0].copy()
                    base['model_id'] = item_id
                    base['product_id'] = df[df['model_id'] == item_id]['product_id'].values[0]
                    rows.append(base)

                input_df = pd.DataFrame(rows)
                X = input_df[['user_id', 'product_id', 'model_id', 'gender', 'age_group',
                              'residence_type', 'ìƒ‰ìƒ', 'ì‚¬ì´ì¦ˆ', 'ì†Œì¬', 'timestamp']].values
                X_tensor = torch.tensor(X, dtype=torch.float32)
                X_tensor = X_tensor.to(device)
                preds = model(X_tensor).cpu().numpy()  # GPUâ†’CPU ë³€í™˜ í›„ numpy

                top_k_idx = preds.argsort()[::-1][:k]
                top_k_items = input_df.iloc[top_k_idx]['model_id'].values
                relevant_items = set(df[(df['user_id'] == user_id) & (df['weight'] > 0)]['model_id'])

                hit = sum([1 for item in top_k_items if item in relevant_items])
                precisions.append(hit / k)

        return sum(precisions) / len(precisions)


    def get_pytorch_auc(model, dataset):
        model.eval()
        y_true, y_score = [], []

        with torch.no_grad():
            for X, y in DataLoader(dataset, batch_size=64):
                X, y = X.to(device), y.to(device)
                pred = model(X).cpu().numpy()

                # weightê°€ 3(êµ¬ë§¤)ì¸ ê²½ìš°ë§Œ 1ë¡œ ì²˜ë¦¬í•˜ê³ , ë‚˜ë¨¸ì§€ëŠ” 0ìœ¼ë¡œ ì²˜ë¦¬
                y_true.extend((y == 3).int().cpu().numpy())  # 3ì´ë©´ 1, ì•„ë‹ˆë©´ 0
                y_score.extend(pred)

        y_true = np.array(y_true)
        y_score = np.array(y_score)

        if len(np.unique(y_true)) < 2:  # í´ë˜ìŠ¤ê°€ í•˜ë‚˜ë§Œ ìˆì„ ê²½ìš°
            print("âš ï¸ AUC ê³„ì‚° ë¶ˆê°€: y_trueì— í´ë˜ìŠ¤ê°€ í•˜ë‚˜ë¿ì…ë‹ˆë‹¤.")
            return 0.0  # AUC ê³„ì‚° ë¶ˆê°€

        try:
            auc = roc_auc_score(y_true, y_score)
        except Exception as e:
            print(f"âš ï¸ AUC ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            auc = 0.0

        return auc


    # âœ… í‰ê°€ ì‹¤í–‰
    pt_precision = get_pytorch_precision_at_k(model, df, k=5)
    pt_auc = get_pytorch_auc(model, RecommendDataset(df))
    print(f"ğŸ“Š Precision@5: {pt_precision:.4f}")
    print(f"ğŸ“Š AUC Score: {pt_auc:.4f}")
